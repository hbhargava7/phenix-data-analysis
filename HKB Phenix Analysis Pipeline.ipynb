{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='monokai', context='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Volumes/HB-ExSSD-T5/2021-04-01 Phenix/HKB 4W SN CAR__2021-03-28T16_00_04-Measurement 1/Images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image & Timecourse Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_and_stitch_image(path, row, col, channel, timepoint, tophat=None, blur=None):\n",
    "    \"\"\"\n",
    "    Retrieve all the tiles for a timepoint and channel and stitch into global image for a measurement.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    directory : path to files\n",
    "    row, col : position in multi-well plate (1-indexed)\n",
    "    channel : index of fluorescence/brightfield channel. Probably on a case by case basis.\n",
    "    timepoint : index of the timepoint to retrieve (1-indexed)\n",
    "    tophat : kernel size to use for tophat flatfield correction (None for no correction)\n",
    "    blur : gaussian width to use for blur flatfield correction (None for no correction)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Pillow Image\n",
    "    \"\"\"\n",
    "    \n",
    "    # Setup tiling parameters (for stitching the tiles)\n",
    "    n_rows = 11\n",
    "    n_cols = 11\n",
    "    tile_size = 1080 # px width of square fov tiles\n",
    "    \n",
    "    # Since the mapping of tile numbers to positions turns out to be arbitrary, we will specify that map here as an n_rows by n_cols array with integral values corresponding to the tile number.\n",
    "    tiling_map = [[2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                 [19, 18, 17, 16, 15, 14, 13, 12, 11],\n",
    "                 [20, 21, 22, 23, 24, 25, 26, 27, 28],\n",
    "                 [36, 35, 34, 33, 1, 32, 31, 30, 29],\n",
    "                 [37, 38, 39, 40, 41, 42, 43, 44, 45],\n",
    "                 [54, 53, 52, 51, 50, 49, 48, 47, 46],\n",
    "                 [55, 56, 57, 58, 59, 60, 61, 62, 63],\n",
    "                 [72, 71, 70, 69, 68, 67, 66, 65, 64]]\n",
    "    \n",
    "    tiling_map = [[-1, -1, -1, 2, 3, 4, 5, 6, -1, -1, -1],\n",
    "                 [-1, 15, 14, 13, 12, 11, 10, 9, 8, 7, -1],\n",
    "                 [-1, 16, 17, 18, 19, 20, 21, 22, 23, 24, -1],\n",
    "                 [35, 34, 33, 32, 31, 30, 29, 28, 27, 26, 25],\n",
    "                 [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46],\n",
    "                 [56, 55, 54, 53, 52, 1, 51, 50, 49, 48, 47],\n",
    "                 [57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67],\n",
    "                 [78, 77, 76, 75, 74, 73, 72, 71, 70, 69, 68],\n",
    "                 [-1, 79, 80, 81, 82, 83, 84, 85, 86, 87, -1],\n",
    "                 [-1, 96, 95, 94, 93, 92, 91, 90, 89, 88, -1],\n",
    "                 [-1, -1, -1, 97, 98, 99, 100, 101, -1, -1, -1]]\n",
    "    \n",
    "    # Read in all the tiles.\n",
    "    # File nomenclature is row : col : tile_number : fluorescence_channel : timepoint\n",
    "    tiles = []\n",
    "    for idx in range(1,n_rows*n_cols+1):\n",
    "        try:\n",
    "            tiles.append(Image.open(path + 'r%02dc%02df%02dp01-ch%isk%ifk1fl1.tiff' % \n",
    "                        (row, col, idx, channel, timepoint)))\n",
    "        except:\n",
    "            tiles.append(Image.fromarray(np.ones((tile_size,tile_size)), 'L'))\n",
    "    \n",
    "    # Perform the flatfield correction as desired.\n",
    "    nt = []\n",
    "    if tophat != None:\n",
    "        for tile in tiles:\n",
    "            kernel100 = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(tophat, tophat))\n",
    "            new_tile = cv2.morphologyEx(np.asarray(tile), cv2.MORPH_BLACKHAT, kernel100)\n",
    "            nt.append(Image.fromarray(new_tile))\n",
    "        tiles=nt\n",
    "        \n",
    "    if blur != None:\n",
    "        for tile in tiles:\n",
    "            inferred_bg = np.array(cv2.blur(np.asarray(tile), (blur, blur)))\n",
    "            tile = np.array(tile)\n",
    "            corrected = np.subtract(tile.astype('int32'), inferred_bg.astype('int32'))\n",
    "            nt.append(corrected)\n",
    "        tiles = nt\n",
    "        \n",
    "    global_image = np.empty((n_cols * tile_size, n_rows * tile_size), dtype='int32')\n",
    "    for y, row in enumerate(tiling_map):\n",
    "        for x, tile_idx in enumerate(row):\n",
    "            x_coord = x * tile_size\n",
    "            y_coord = y * tile_size\n",
    "            tile = tiles[tile_idx-1]\n",
    "            global_image[y_coord:y_coord+tile_size, x_coord:x_coord+tile_size] = tiles[tile_idx-1]\n",
    "\n",
    "    return global_image\n",
    "\n",
    "def retrieve_timecourse(path, row, col, channel, start, end, tophat=None, blur=None):\n",
    "    \"\"\"\n",
    "    Wrapper for retrieve_and_stitch_image that gets the entire timecourse for a channel.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Same as retrieve_and_stitch_image, and also:\n",
    "    start : first frame to get (1-indexed)\n",
    "    end : last timepoint to get\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List of Pillow Images in order.\n",
    "    \"\"\"\n",
    "    timecourse = []\n",
    "    for t in tqdm(range(start, end+1)):\n",
    "        image = retrieve_and_stitch_image(path, row, col, channel, t, tophat, blur)\n",
    "        timecourse.append(image)\n",
    "        \n",
    "    return timecourse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import animation, rc\n",
    "import matplotlib.colors\n",
    "\n",
    "def render_movie_for_timecourse(tc, filename, size=(2250,2000)):\n",
    "    \"\"\"\n",
    "    Given a timecourse (e.g. from retrieve_timecourse), render a movie.\n",
    "    \"\"\"\n",
    "    \n",
    "    data = []\n",
    "    for img in tc:\n",
    "        img = cv2.resize(img, dsize=size, interpolation=cv2.INTER_NEAREST)\n",
    "        data.append(img)\n",
    "        \n",
    "    # Normalize the colormap based on timepoint 24\n",
    "    _vmin = np.mean(np.asarray(data[24]))-2*np.std(np.asarray(data[24]))\n",
    "    _vmax = np.mean(np.asarray(data[24]))+2*np.std(np.asarray(data[24]))\n",
    "    \n",
    "    n_frames = len(data)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plot = plt.imshow(data[0], vmax=_vmax, vmin=_vmin, cmap='viridis')\n",
    "    text = plt.text(.1, -.1, '', fontsize=20, transform=plt.gca().transAxes)\n",
    "    plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "    def init():\n",
    "        plot.set_data(data[0])\n",
    "        text.set_text('t=0h')\n",
    "        return [plot, text]\n",
    "\n",
    "    def update(j):\n",
    "        plot.set_data(data[j])\n",
    "        text.set_text('t=%ih'%(j+1))\n",
    "        return [plot]\n",
    "\n",
    "    anim = FuncAnimation(fig, update, init_func=init, frames=n_frames, interval=500, blit=True)\n",
    "    anim.save('%s.mp4'%(filename), dpi=300)\n",
    "    print('Animation rendered successfully: %s' % filename)\n",
    "    \n",
    "def render_overlay_movie(tc_base, tc_overlay, filename, size=(2250,2000)):\n",
    "    \"\"\"\n",
    "    Overlay tc_overlay on tc_base and render an animation. E.g. GFP over brightfield.\n",
    "    This method drops pixels below μ - 1σ in the overlay channel, and overlays at 50% opacity.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Resize all the images\n",
    "    base_data = []\n",
    "    overlay_data = []\n",
    "    for base_img, overlay_img in zip(tc_base, tc_overlay):\n",
    "        \n",
    "        base_img = cv2.resize(base_img, dsize=(2250, 2000), interpolation=cv2.INTER_NEAREST)\n",
    "        overlay_img = cv2.resize(overlay_img, dsize=(2250, 2000), interpolation=cv2.INTER_NEAREST)\n",
    "                \n",
    "        # Drop pixels less than the mean in the overlay image\n",
    "        overlay_img = np.array(overlay_img)\n",
    "        overlay_img[overlay_img < np.mean(overlay_img)-np.std(overlay_img)] = 0\n",
    "        \n",
    "        base_data.append(base_img)\n",
    "        overlay_data.append(overlay_img)\n",
    "    \n",
    "    # Make colormaps\n",
    "    cmap_base = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\", \"white\"])\n",
    "    cmap_overlay = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [(0,0,0,0), \"green\"])\n",
    "    \n",
    "    # Generate colormap limits based on timepoint 24\n",
    "    baselim = [np.mean(np.asarray(base_data[24]))-2*np.std(np.asarray(base_data[24])), np.mean(np.asarray(base_data[24]))+2*np.std(np.asarray(base_data[24]))]\n",
    "    overlaylim = [np.mean(np.asarray(overlay_data[24]))-2*np.std(np.asarray(overlay_data[24])), np.mean(np.asarray(overlay_data[24]))+2*np.std(np.asarray(overlay_data[24]))]\n",
    "    \n",
    "    n_frames = len(base_data)\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plot = plt.imshow(base_data[0], clim=baselim, cmap=cmap_base, alpha=1)\n",
    "    plt.imshow(overlay_data[0], clim=overlaylim, cmap=cmap_overlay, alpha=.5)\n",
    "\n",
    "    text = plt.text(.1, -.1, '', fontsize=20, transform=plt.gca().transAxes)\n",
    "    \n",
    "    def init():\n",
    "        plt.imshow(base_data[0], clim=baselim, cmap=cmap_base, alpha=1)\n",
    "        plt.imshow(overlay_data[0], clim=overlaylim, cmap=cmap_overlay, alpha=.5)\n",
    "        text.set_text('t=0h')\n",
    "        return [plot, text]\n",
    "\n",
    "    def update(j):\n",
    "        plt.clf()\n",
    "        plt.imshow(base_data[j], clim=baselim, cmap=cmap_base, alpha=1)\n",
    "        plt.imshow(overlay_data[j], clim=overlaylim, cmap=cmap_overlay, alpha=.5)\n",
    "        plt.text(.1, -.1, 't=%ih'%(j+1), fontsize=20, transform=plt.gca().transAxes)\n",
    "        return [plot]\n",
    "\n",
    "    anim = FuncAnimation(fig, update, init_func=init, frames=n_frames, interval=500, blit=True)\n",
    "    anim.save('%s.mp4'%(filename), dpi=300)\n",
    "    print('Overlay animation rendered successfully: %s' % filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions (visualization, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz(img, dpi=300, save=None, cmap=None):\n",
    "    plt.rcParams[\"axes.grid\"] = False\n",
    "\n",
    "    _vmin = np.mean(np.asarray(img))-2*np.std(np.asarray(img))\n",
    "    _vmax = np.mean(np.asarray(img))+2*np.std(np.asarray(img))\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10),dpi=dpi)\n",
    "    colormap = 'viridis'\n",
    "    if cmap != None:\n",
    "        colormap = cmap\n",
    "    plot = plt.imshow(img, vmax=_vmax, vmin=_vmin, cmap=colormap)\n",
    "    \n",
    "    if save != None:\n",
    "        plt.savefig('%s.png'%save, dpi=dpi)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation - Image Retrieval, Animation, Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_overlay(gfp, bf, filename, color):\n",
    "    # Make colormaps for brightfield, segmentation, and target channels\n",
    "    cmap_base = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\", \"white\"])\n",
    "    cmap_red = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [(0,0,0,0), color])\n",
    "\n",
    "    # Calculate color thresholds (μ-2σ, μ+2σ)\n",
    "    bfmin = np.mean(np.asarray(bf))-2*np.std(np.asarray(bf))\n",
    "    bfmax = np.mean(np.asarray(bf))+2*np.std(np.asarray(bf))\n",
    "\n",
    "    gfpmin = np.mean(np.asarray(gfp))-2*np.std(np.asarray(gfp))\n",
    "    gfpmax = np.mean(np.asarray(gfp))+2*np.std(np.asarray(gfp))\n",
    "\n",
    "    # Make the plot\n",
    "    fig = plt.figure(figsize=(10,10),dpi=1000)\n",
    "    plot = plt.imshow(bf, vmax=bfmax, vmin=bfmin, cmap=cmap_base)\n",
    "    plt.imshow(gfp, vmax=gfpmax, vmin=gfpmin, cmap=cmap_red, alpha=.75)\n",
    "    plt.savefig('%s.tiff'%filename, dpi=1000)\n",
    "    plt.close()\n",
    "def make_triple_overlay(gfp, mCh, bf, filename):\n",
    "    # Make colormaps for brightfield, segmentation, and target channels\n",
    "    cmap_base = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"black\", \"white\"])\n",
    "    cmap_red = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [(0,0,0,0), 'red'])\n",
    "    cmap_green = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [(0,0,0,0), 'green'])\n",
    "    # Calculate color thresholds (μ-2σ, μ+2σ)\n",
    "    bfmin = np.mean(np.asarray(bf))-2*np.std(np.asarray(bf))\n",
    "    bfmax = np.mean(np.asarray(bf))+2*np.std(np.asarray(bf))\n",
    "\n",
    "    gfpmin = np.mean(np.asarray(gfp))-2*np.std(np.asarray(gfp))\n",
    "    gfpmax = np.mean(np.asarray(gfp))+2*np.std(np.asarray(gfp))\n",
    "\n",
    "    mchmin = np.mean(np.asarray(mCh))-2*np.std(np.asarray(mCh))\n",
    "    mchmax = np.mean(np.asarray(mCh))+2*np.std(np.asarray(mCh))\n",
    "    \n",
    "    # Make the plot\n",
    "    fig = plt.figure(figsize=(10,10),dpi=1000)\n",
    "    plot = plt.imshow(bf, vmax=bfmax, vmin=bfmin, cmap=cmap_base)\n",
    "    plt.imshow(gfp, vmax=gfpmax, vmin=gfpmin, cmap=cmap_green, alpha=.5)\n",
    "    plt.imshow(mCh, vmax=mchmax, vmin=mchmin, cmap=cmap_red, alpha=.5)\n",
    "    plt.savefig('%s.tiff'%filename, dpi=1000)\n",
    "    plt.close()\n",
    "# make_overlay(edges1, img, 'edges1_overlay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('channel 1')\n",
    "img = retrieve_and_stitch_image(data_path, 1, 1, 1, 1)\n",
    "viz(img, cmap='viridis', save='channel_1')\n",
    "print('channel 2')\n",
    "img = retrieve_and_stitch_image(data_path, 1, 1, 2, 1)\n",
    "viz(img, cmap='viridis', save='channel_2')\n",
    "print('channel 3')\n",
    "img = retrieve_and_stitch_image(data_path, 1, 1, 3, 1)\n",
    "viz(img, cmap='viridis', save='channel_3')\n",
    "print('channel 4')\n",
    "img = retrieve_and_stitch_image(data_path, 1, 1, 4, 1)\n",
    "viz(img, cmap='viridis', save='channel_4')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
